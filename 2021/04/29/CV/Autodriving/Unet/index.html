<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="U-Net模型详解模型结构(Encoder-Decoder)U-Net最早是在医学图像领域提出用于医学图像的语义分割的模型，它的网络结构如下图所示。输入的是572x572维的灰度图，经过5层卷积，每层都是用3x3的卷积核，且不加padding，因此每次卷积过后图像维度会减2，每层卷积后会是用2x2的MaxPooling。第五层卷积结束后图像维度是28x28，通道数是1024，对其做2x2的上采样卷">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/2021/04/29/CV/Autodriving/Unet/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="U-Net模型详解模型结构(Encoder-Decoder)U-Net最早是在医学图像领域提出用于医学图像的语义分割的模型，它的网络结构如下图所示。输入的是572x572维的灰度图，经过5层卷积，每层都是用3x3的卷积核，且不加padding，因此每次卷积过后图像维度会减2，每层卷积后会是用2x2的MaxPooling。第五层卷积结束后图像维度是28x28，通道数是1024，对其做2x2的上采样卷">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="f:/blog/CV/Autodriving/imgs/Unet.png">
<meta property="og:image" content="f:/blog/CV/Autodriving/imgs/overlap-tile.png">
<meta property="og:image" content="http://example.com/2021/04/29/CV/Autodriving/Unet/.%5Cimgs%5Chourglass.png">
<meta property="og:image" content="http://example.com/2021/04/29/CV/Autodriving/Unet/.%5Cimgs%5Cresnet.png">
<meta property="og:image" content="http://example.com/2021/04/29/CV/Autodriving/Unet/.%5Cimgs%5Cresidual.png">
<meta property="og:image" content="http://example.com/2021/04/29/CV/Autodriving/Unet/.%5Cimgs%5Cbottleneck.png">
<meta property="og:image" content="http://example.com/2021/04/29/CV/Autodriving/Unet/imgs/res2net.png">
<meta property="og:image" content="http://example.com/2021/04/29/CV/Autodriving/Unet/imgs/ResNeXt.png">
<meta property="og:image" content="f:/blog/CV/Autodriving/imgs/Se-Resnet.png">
<meta property="og:image" content="f:/blog/CV/Autodriving/imgs/se-module.png">
<meta property="og:image" content="f:/blog/CV/Autodriving/imgs/sk-resnet.png">
<meta property="og:image" content="f:/blog/CV/Autodriving/imgs/sk-module.png">
<meta property="og:image" content="f:/blog/CV/Autodriving/imgs/resnest.png">
<meta property="og:image" content="f:/blog/CV/Autodriving/imgs/UNet++.png">
<meta property="article:published_time" content="2021-04-29T03:06:20.104Z">
<meta property="article:modified_time" content="2021-04-08T09:37:23.457Z">
<meta property="article:author" content="Cheng Zixu">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="f:/blog/CV/Autodriving/imgs/Unet.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Buscar"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Buscar"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-CV/Autodriving/Unet" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/04/29/CV/Autodriving/Unet/" class="article-date">
  <time class="dt-published" datetime="2021-04-29T03:06:20.104Z" itemprop="datePublished">2021-04-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="U-Net模型详解"><a href="#U-Net模型详解" class="headerlink" title="U-Net模型详解"></a>U-Net模型详解</h1><h3 id="模型结构-Encoder-Decoder"><a href="#模型结构-Encoder-Decoder" class="headerlink" title="模型结构(Encoder-Decoder)"></a>模型结构(Encoder-Decoder)</h3><p>U-Net最早是在医学图像领域提出用于医学图像的语义分割的模型，它的网络结构如下图所示。输入的是572x572维的灰度图，经过5层卷积，每层都是用3x3的卷积核，且不加padding，因此每次卷积过后图像维度会减2，每层卷积后会是用2x2的MaxPooling。第五层卷积结束后图像维度是28x28，通道数是1024，对其做2x2的上采样卷积（可参考<a href="./%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E8%BD%A6%E9%81%93%E7%BA%BF%E5%88%86%E5%89%B2%E6%8A%80%E6%9C%AF.md">转置卷积</a>），得到图像维度是56x56，通道数是512的特征图。再将第四层卷积的输出经过crop操作将64x64变为56x56后，与第五层上采样后的特征图进行concat操作，得到通道为1024大小为56x56的特征图。再对其进行同样的卷积、上采样并与再上一层的输出crop后进行concat，总共进行4次上采样。最后一层采用1x1的卷积，输出通道为2，大小为388x388的医学图像语义分割图。</p>
<p><img src="F:\blog\CV\Autodriving\imgs\Unet.png"></p>
<h3 id="Overlap-tile-strategy"><a href="#Overlap-tile-strategy" class="headerlink" title="Overlap-tile strategy"></a>Overlap-tile strategy</h3><p>Overlap-tile strategy是医学数字图像处理领域常用的策略。U-Net的图片在输入网络前做了mirror-padding的图像处理，这是生物医学领域中常用的一种方法。原理是将图像边缘的一些像素做了一些对称复制的镜像padding，增大了图片的尺寸。它的好处是避免zero-padding引入的无用信息，因为在医学图像领域，图像边缘都会有不完整细胞，若使用通常的zero-padding，在计算中会降低不完整细胞边缘的权重，因此通常会采用mirror-padding。U-Net中的输入图片尺度是经过mirror-padding后的572x572，而输出维度388x388则是mirror-padding前原始图像的维度。</p>
<p><img src="F:\blog\CV\Autodriving\imgs\overlap-tile.png"></p>
<h2 id="U-Net相似网络"><a href="#U-Net相似网络" class="headerlink" title="U-Net相似网络"></a>U-Net相似网络</h2><h3 id="Hourglass"><a href="#Hourglass" class="headerlink" title="Hourglass"></a>Hourglass</h3><p>用于人体姿态估计，用于解决关键点定位问题。</p>
<p><img src=".%5Cimgs%5Chourglass.png"></p>
<h3 id="Pix2Pix"><a href="#Pix2Pix" class="headerlink" title="Pix2Pix"></a>Pix2Pix</h3><p>主要是用于做图像生成。</p>
<h2 id="UNet网络结构修改"><a href="#UNet网络结构修改" class="headerlink" title="UNet网络结构修改"></a>UNet网络结构修改</h2><h3 id="BackBone"><a href="#BackBone" class="headerlink" title="BackBone"></a>BackBone</h3><h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4><p>当神经网络的深度越深的时候，会发现其效果可能还没有没那么深的模型训练的效果好，这是由于网络训练过程中产生的梯度消失和梯度爆炸导致的。ResNet提出了残差结构，如下图，这个结构能让网络在深层的时候更容易学习与优化。</p>
<p><img src=".%5Cimgs%5Cresnet.png"></p>
<p>从下图的实验结果可以看出，34层的深度网络在没添加Residual结构的时候，训练时的错误率是比18层的网络要高的，而完全没达到网络越深模型效果越好的预期。但是加入了Residual结构后，ResNet-34的网络训练的正确率可以明显低于ResNet-18网络的训练效果，使得网络的深度发挥了优势。</p>
<p><img src=".%5Cimgs%5Cresidual.png"></p>
<p>但作者发现使用basic block后增大了许多的计算量，于是他设计了一种bottleneck结构，在进行运算时，先用1x1的卷积将数据降维，进行完3x3卷积之后再将数据升回原来的维度，如下图。<img src=".%5Cimgs%5Cbottleneck.png"></p>
<h3 id="Variations-of-ResNet"><a href="#Variations-of-ResNet" class="headerlink" title="Variations of ResNet"></a>Variations of ResNet</h3><h4 id="Res2Net"><a href="#Res2Net" class="headerlink" title="Res2Net"></a>Res2Net</h4><p>Res2Net实际中用的并不多。它的原理是将1x1卷积后的结果分成4组，第一组直接复制，第二组经过一个3x3卷积，第三组先跟第二组的结果做融合后经过一个3x3卷积，第四组跟第三组的结果做融合后经过一个3x3卷积，最后将四组结果再拼起来。</p>
<p>Res2Net运用了scale的思想，我们知道两个3x3的卷积串联后的感受野等价于一个5x5的卷积，三个3x3的卷积串联后的感受野等价于一个7x7的卷积。于是Res2Net的操作相当于从不同感受野尺度上提取的特征后进行融合。</p>
<img src=".\imgs\res2net.png" style="zoom:33%;" />

<h4 id="ResNeXt"><a href="#ResNeXt" class="headerlink" title="ResNeXt"></a>ResNeXt</h4><p>ResNeXt实际中使用的比较多，它采用的是分组卷积(Group Convolution)的思想。分组卷积中，每组卷积中的特征信息是隔离的，最后再将每组卷积进行相加。</p>
<img src=".\imgs\ResNeXt.png" style="zoom:33%;" />

<p>这样操作的目的是减小计算量。</p>
<h4 id="SE-ResNet"><a href="#SE-ResNet" class="headerlink" title="SE-ResNet"></a>SE-ResNet</h4><p>Squeeze-and-Excitation Module（SE Module），可参考<a href="../facebagnet&attention/SENet.md">SENet</a>。</p>
<img src="F:\blog\CV\Autodriving\imgs\Se-Resnet.png" style="zoom:33%;" />

<p><img src="F:\blog\CV\Autodriving\imgs\se-module.png"></p>
<h4 id="SK-ResNet"><a href="#SK-ResNet" class="headerlink" title="SK-ResNet"></a>SK-ResNet</h4><p>Selective Kernel Module (SK Module)，原理是将Residual Module中的3x3卷积替换成SK Module来实现Split Attention。 </p>
<img src="F:\blog\CV\Autodriving\imgs\sk-resnet.png" style="zoom:33%;" />

<p>SK Module的具体结构如下图，对输入的特征分别做3x3和5x5的卷积，然后将卷积结果相加，经过Global Average Pooling和全连接后，通过Softmax得到之前3x3和5x5的卷积结果的Attention。对应的Attention相乘后再相加得到带有Split Attention的输出特征。</p>
<p><img src="F:\blog\CV\Autodriving\imgs\sk-module.png"></p>
<p>SK-ResNet作者认为不同尺度的卷积可以提取到不同的特征，通过Softmax可以实现对这些不同特征的选择。</p>
<h4 id="ResNeSt"><a href="#ResNeSt" class="headerlink" title="ResNeSt"></a>ResNeSt</h4><p>将ResNeXt的分组卷积和SK-ResNet中的SK Module结合起来。</p>
<p><img src="F:\blog\CV\Autodriving\imgs\resnest.png"></p>
<h2 id="UNet"><a href="#UNet" class="headerlink" title="UNet++"></a>UNet++</h2><p>UNet++的原理是将不同深度的UNet融合在一个网络中，可以得到不同深度UNet网络的融合结果，如下图。</p>
<p><img src="F:\blog\CV\Autodriving\imgs\UNet++.png"></p>
<p>用4层深度的UNet++ L4来举例，第一层除了X(0,0)，其他的都是与原图尺寸相同的、经过不同网络深度的输出，这四个输出都用于计算Loss。四个输出可以做融合也可以用来做剪枝。剪枝就是如果发现X(0,3)和X(0,4)的输出大致相同，则可以将L4的分支剪掉，在做预测的时候就只预测到L3就好。</p>
<p>所以UNet++最大的特点就是，训练的时候可以训练4层，预测的时候可以按照训练效果和场景需求，只使用1/2/3层的预测值。这解决了当训练UNet模型的时候，不知道选择多深的网络合适从而避免了训练多个深度的模型，而实现只训练一个模型达到不同深度的训练效果。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/04/29/CV/Autodriving/Unet/" data-id="cko2b3cum0004p4vc4ay8f3vl" data-title="" class="article-share-link">Compartir</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/04/29/CV/Autodriving/%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E8%BD%A6%E9%81%93%E7%BA%BF%E5%88%86%E5%89%B2%E6%8A%80%E6%9C%AF/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Nuevo</strong>
      <div class="article-nav-title">
        
          (no title)
        
      </div>
    </a>
  
  
    <a href="/2021/04/29/CV/Autodriving/segmentation/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Viejo</strong>
      <div class="article-nav-title"></div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archivos</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">April 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Posts recientes</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/04/29/CV/YOLO/Yolo%E7%B3%BB%E5%88%97%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/04/29/CV/train/model-train/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/04/29/CV/train/data-preprocessing/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/04/29/CV/RCNN-family/RCNN%EF%BC%8CFast%20RCNN%EF%BC%8CFaster%20RCNN%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/04/29/CV/facebagnet&attention/SENet/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 Cheng Zixu<br>
      Construido por <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>